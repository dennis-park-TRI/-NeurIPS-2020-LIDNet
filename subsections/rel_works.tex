

\cite{fcn_cvpr, rcnn_1} were one of the first works to introduce deep architectures for the task of semantic segmentation. %, surpassing previous non-deep methods~\cite{non_deep_sem_seg, non_deep_sem_seg_2}. 
Multiple generations of work~\cite{deeplab_v1, deeplab_v2, pspnet, unet}, have further improved the performance, albeit at the cost of more computation mode labelled data requirement. A large corpus of previous literature alleviates the data bottleneck via semi-supervised approaches~\cite{semi_sup_seg_1, semi_sup_seg_2}, domain adaptation~\cite{domain_seg_1, domain_seg_2, domain_seg_3, domain_seg_nips_1, domain_seg_nips_2, multi_domain_seg}, and data augmentation~\cite{semi_aug_1, semi_aug_2}.

Works such as~\cite{noisy_self}, assuage the label bottleneck via creation of pseudo-labels for a large set of unlabelled images. This pseudo-labelling utilizes the semantic knowledge in the labelled dataset. In contrast, works such as~\cite{lp_eccv, lp_iccvw, lp_2013} propose label propagation, where geometric approaches such as video-prediction~\cite{sdc_net}, are utilized for generating labels.
%In such works, the geometric knowledge is utilized for generating pseudo-labels. 
To the best of our knowledge, our work is the first to utilize both the semantic and geometric understanding to propagated labels.
%Mention gal\_multitask.
The combination of semantic and geometric understanding has been explore in the past for other tasks~\cite{future_seg, sem_warp, feelvos2019}. Our chief distinction is the propagation of ground-truth labels, which in turn necessitates a novel cyclic label consistency-based loss. 
%Furthermore, since our process can be performed offline, lack of compute bottleneck allow us to explore highly performative modeling inspired from recent generative modelling methods~\cite{pix2pix, spades}. 
The concept of cyclic consistency has been used previously for learning object embeddings~\cite{CVPR2019_CycleTime}, and video interpolation~\cite{cycle_vid_interp}. Our work is inspired from~\cite{CVPR2019_CycleTime}, where cyclic consistency is used for learning object embeddings using a robust tracker. However, unlike~\cite{CVPR2019_CycleTime}, we address the noisy nature of our tracking/geometric modelling method itself.

Previous works deal with the noise in propagated labels by defining heuristics such as trust-factor~\cite{lp_eccv} or label-relaxation~\cite{nvidia_cvpr19}. In our work, we propose a principled approach based on modelling the label uncertainty. Recently,~\cite{gal_main, gal_multitask, uncer_nips_2, uncer_nips_3} have explored modelling of uncertainty in the context of deep learning models. Furthermore, works such as~\cite{uncer_label_1, uncer_label_2}, have explored the relation between aleatoric uncertainty, and label noise. In~\cite{uncer_label_1}, the authors propose a sophisticated noise model for dealing with noisy labelling in the task of keypoint matching. While we also utilize aleatoric uncertainty for dealing with label noise, our approach is formulated for handling multiple noisy label distributions at the same time with minimal computational overhead, unlike~\cite{uncer_label_1}.
